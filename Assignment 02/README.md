# DH 250 Assignment 2 - Garrett Romero
## Math is fun Moderated Usability Test 

### Introduction
---- 
In today's COVID-19 reality, remote learning has become required and additional educational resources are becoming even more important to facilitate effective this new reality. The Math is fun website is an educational resource for mathematics supplemental learning. It provides math examples, simple how-to videos, math worksheets and quizzes and more. My initial impressions are that I found the website fairly straight forward and did not overwhelm me with information based on the landing page. However, after conducting the heuristic evaluation, based on Jakob Nielsen's 10 principles, I found a few violations that potentially impacted usability of the website. Specifically:

* **User Control & Freedom:** Mathisfun does provide user control and freedom, however, it is not consistent. Upon selecting the various categories displayed (algebra, geometry, etc.) on the header bar, a user does have directional functions to move forward or backwards with the content associated to it. What becomes conflictual is that there is too much user control and freedom while simultaneously lacking it.
* **Match between system and the real world:** The child pages linking to the header bar tend to deviate from this aspect. The design logos are not placed in a uniform manner, which may have the user engage visually with the content in a left-to-right or right-to-left manner.
* **Recognition rather than recall:** The area where Mathisfun does rely on recall versus recognition is when the navigational arrows to switch between content pages become non-existent. Once the arrows are removed, then the user needs to remember how to get back to previous content that was explored.
* **Consistency and standards:** The consistency issue that should be addressed is with the horizontal direction arrows that was discussed in the ‘User control and freedom’ section.

----
### Purpose for Usability Testing
----
The purpose of the usability test for the Mathisfun website is to confirm whether or not the violations I identified from the heuristic evaluation are valid. Through moderating a usability test with a potential user, it will give me actionable insight and allow me to ask questions along the way that will gain further understanding to the issues that might be present on the website. More importantly, the usability test is structured around three scenarios to identify the pain points based on ease of use, efficiency, and information seeking behavior. These specific scenarios are relatable to the heuristic violations identified and will allow me to recommend actionable steps to improve the usability of the Mathisfun website to relevant stakeholders. 

----
### Methodology
----
To perform the Mathisfun usability test, recruitment will be focused on identifying a woman who fits the demographics identified from the [heuristic evaluation](https://github.com/elco7985/DH250-Romero_Garrett/blob/main/README.md). Most of the tasks of the usability test will be through a custom-made Google form to present the script of the usability test, inform the participant of the nature of the research, guarantee participant safety, to perform the usability test and capture the data. The usability test will be conducted on the Zoom video conference software. This is meant to protect participant(s) due to social distancing recommendations in light of the COVID-19 pandemic. The features that will be used through Zoom are screen sharing, audio and video recording, and the chat box.

Upon meeting with the research participant on Zoom, the moderator will inform the participant of the scope and purpose of the study and request consent to conduct and record the study through the Zoom application. After informing the participant the purpose of the study and receiving consent, the moderator will walk through the various tasks with the participant, which include pre-questionnaire  questions, scenario-based tasks, post-questionnaire  questions, card selections, and demographics. These tasks and scenarios will capture data based on ease of use, information architecture, efficiency of navigating the website, intuitiveness based on website design, and aesthetics of the website. 

Lastly, interviewing techniques will be utilized to allow active listening and to engage in impromptu questioning that could further the research beyond what the script and scenarios engage with. Questioning techniques, such as laddering, open-ended, and "going down the rabbit hole", will be used throughout the entire process.



----
### Survey Link
----
To access the survey link, click [here!](https://docs.google.com/forms/d/e/1FAIpQLScG0jZh4hLh9-Mn6lH8054MqrU6V1xO1QJDNMW2LouDm9u7pA/viewform)

----
### Video Recording
----
To access the video recording, please click [here!](https://drive.google.com/file/d/1F4KBqz1NnSLknXbvfSRyWWU8qg1VVjiz/view?usp=sharing)

----
### Reflections
----
The study in many ways accomplished what the research goal was - to confirm and find pain points throughout the website. I received great feedback from my participant. I knew there was more descriptors he wanted to use that were not available and so I asked him if he cared to share any additional thoughts that were on his mind. 

* **He explicitly stated,** “I thought the site was antiquated”; “Dated and uninviting. Would only visit once. How contemporary is this going be towards modern learning when everything just looks like it is from 1993. It looks like one of the original websites. And if you're trying to tell me math is fun, there is not a single fun thing navigating your site. If this is exactly why kids hate math, it is just so stiff and there is no dimension, no depth.”


The participant also affirmed my suspicions about user control and freedom, graphics placement, recognition vs. recall, the navigation of the website being too cumbersome and difficult. What was surprising is that I was not planning on the user stumbling onto user control and freedom issues with a Scenario 2. The next scenario was going to engage with this particular violation. However, I did state that this particular violation was rampant throughout the website so it makes sense that we found related violations along the way. Another surprising aspect that I did not capture with initial heuristic evaluation was the participant unable to locate home button/logo during one of the scenarios. If I had to re-adjust my severity ranking on the heuristic evaluation, I would escalate the Consistency and Standards principle as something that needs to be addressed immediately.

In executing the research, I should have been more mindful about the research setting. Specifically, the process of conducting the usability test on two different screens while using Zoom. During one part of the scenario, the participant was supposed to engage with the horizontal navigation arrows and due to the reduction of the website space due to splitting screens, that particular functionality was not displayed and the user was not able to visually see it or engage with it. While it was a mistake, I still felt it was a good mistake to make. It serves as a reminder to always be thorough in your test environment for research before implementing it. Crafting the scenarios was also challenging. I had to hone in on my empathy skills and put myself in the shoes of a teacher to make sure the scenarios made sense. I ran the scenarios by my aunt, who recommended and uses the Mathisfun website, to make sure they made sense and were not unrealistic. 

Another issue that came up during the research process is procuring research participation. My target audience for the research are teachers who are middle-aged women, so my initial research subject through recruitment met that criteria. However, my research subject dropped out of the study due to personal reasons and I had to act quickly to get a research participant. While the participant I used for the study was middle-aged, he was male and not a teacher. For future research, I know that I need to target that audience. 

Lastly, I was able to utilize some elements of user interviewing techniques into the usability test. Specifically, I asked impromptu questions I felt were needed to be asked, for example “Did you experience any type of emotions while completing the scenarios?” Due to engaging in these techniques, I allowed the user to fully explain himself and never cut him off at any point. It also engaged in a form of empathy to where I really wanted to know how he felt on different scale of measurement. One thing I would like to add into the usability test is a different set of card selections where it touches on emotion. I feel that will add more depth to the study in a structured way.

More broadly, this exercise really reinforced how beneficial it is to conduct a heuristic evaluation first, in order to craft and implement the usability test. The violations identified from the heuristic evaluation were insightful and allowed me to design the study in an impactful way that produced great results. While Dr. Cho stated using the heuristic evaluation as the foundation to craft the usability test, I found it extremely rewarding of actually engaging in this process, which added more depth to my knowledge in UX Design and Research.  
